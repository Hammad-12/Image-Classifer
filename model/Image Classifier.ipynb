{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BSd6G_Y0AhR-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7iCIA4Sv2COi"
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "  images = []\n",
    "  labels = []\n",
    "  categories = []\n",
    "\n",
    "  data_dir = 'D:\\PROJECTS\\IMAGE CLASSIFIER\\Data'\n",
    "  for folder in os.listdir(data_dir):\n",
    "    categories.append(folder)\n",
    "\n",
    "#   counter = 0\n",
    "  for i in categories:\n",
    "    path = os.path.join(data_dir, i)\n",
    "    for img in os.listdir(path):\n",
    "      image = cv2.imread(os.path.join(path, img))\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      image = cv2.resize(image, (224, 224))\n",
    "      images.append(image)\n",
    "      labels.append(i)\n",
    "#       counter += 1\n",
    "#       if counter == 200:\n",
    "#         counter = 0\n",
    "#         break\n",
    "    print('folder completed!')\n",
    "  images = np.array(images)\n",
    "  labels = np.array(labels)\n",
    "  print(categories)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSmygn5V3c4b",
    "outputId": "d06f31ec-ced2-4373-b2e3-76ce5ccc209b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder completed!\n",
      "folder completed!\n",
      "folder completed!\n",
      "folder completed!\n",
      "['cloudy', 'Rain', 'shine', 'sunrise']\n"
     ]
    }
   ],
   "source": [
    "images, labels = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-un4qmo34w3Z",
    "outputId": "565d68f6-946a-42ab-dd14-2e753a21763b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(1120, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(images):\n",
    "  model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "  vgg16_features = model.predict(images)\n",
    "  print(model.summary())\n",
    "  return vgg16_features\n",
    "\n",
    "features = extract_features(images)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhUa848k472e",
    "outputId": "85175dea-0eab-40f2-d712-cf801a40c59b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 25088)\n"
     ]
    }
   ],
   "source": [
    "examples = features.shape[0]\n",
    "_features = 1\n",
    "for ele in features.shape[1:]:\n",
    "  _features *= ele\n",
    "features = features.flatten().reshape((examples, _features))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VMmasm_HIiP",
    "outputId": "dfac8a36-9877-4903-9ec2-e1f26a7d5616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for SVC() is:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Rain       1.00      0.95      0.98        63\n",
      "      cloudy       0.96      0.94      0.95        90\n",
      "       shine       0.91      0.97      0.94        76\n",
      "     sunrise       0.97      0.96      0.97       107\n",
      "\n",
      "    accuracy                           0.96       336\n",
      "   macro avg       0.96      0.96      0.96       336\n",
      "weighted avg       0.96      0.96      0.96       336\n",
      "\n",
      "\n",
      "\n",
      "[[ 60   1   1   1]\n",
      " [  0  85   3   2]\n",
      " [  0   2  74   0]\n",
      " [  0   1   3 103]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, stratify=labels, random_state=1)\n",
    "\n",
    "# classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(),\n",
    "#     DecisionTreeClassifier(),\n",
    "#     RandomForestClassifier(),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GradientBoostingClassifier(),\n",
    "#     XGBClassifier(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n",
    "# ]\n",
    "\n",
    "# for model in classifiers:\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     print(f'The Classification Report for {model} is:')\n",
    "#     print('\\n')\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print('\\n')\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print('\\n')\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'The Classification Report for {model} is:')\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fFOkVdjF1JdE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/PROJECTS/IMAGE CLASSIFIER/model/model_joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'D:/PROJECTS/IMAGE CLASSIFIER/model/model_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj = joblib.load('D:\\PROJECTS\\IMAGE CLASSIFIER\\model\\model_joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sunrise'], dtype='<U7')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('D:/PROJECTS/IMAGE CLASSIFIER/Data/sunrise/sunrise15.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "\n",
    "print(image.shape)\n",
    "def extract_features(image):\n",
    "  model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "  vgg16_features = model.predict(image)\n",
    "  print(model.summary())\n",
    "  return vgg16_features\n",
    "\n",
    "image = image.reshape(-1, 224, 224, 3)\n",
    "features = extract_features(image)\n",
    "features = features.reshape(1, -1)\n",
    "prediction = mj.predict(features)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Hammad_Masood.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
